{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Szozan/2d-strategic-plan/blob/main/deliverables/Step_9_PDF_Transcript_to_Score.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script ingests a PDF transcript and has ChatGPT generate scores based on a rubric. If the PDF is too large, this script breaks it up into smaller chunks."
      ],
      "metadata": {
        "id": "tLy602MBmDBT"
      },
      "id": "tLy602MBmDBT"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai\n",
        "!pip install langchain-community\n",
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsuN2Xi2oa4S",
        "outputId": "9c331a27-89e6-481b-b904-208520ef78fd",
        "collapsed": true
      },
      "id": "YsuN2Xi2oa4S",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.7-py3-none-any.whl (983 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.6/983.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.35.13-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.12 (from langchain)\n",
            "  Downloading langchain_core-0.2.13-py3-none-any.whl (357 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.9/357.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.85-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.12->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, h11, jsonpatch, httpcore, langsmith, httpx, openai, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.7 langchain-core-0.2.13 langchain-text-splitters-0.2.2 langsmith-0.1.85 openai-1.35.13 orjson-3.10.6\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.7)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.13)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.85)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain-community) (2.8.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain-community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community) (2.20.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.7 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tiktoken can convert text into tokens to transmit to OpenAI"
      ],
      "metadata": {
        "id": "DCYuURTnoLKw"
      },
      "id": "DCYuURTnoLKw"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx1Rvplqso-6",
        "outputId": "e64af193-74f0-4883-a44d-08ddd1a9c5f6",
        "collapsed": true
      },
      "id": "vx1Rvplqso-6",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A library to do similarity matching"
      ],
      "metadata": {
        "id": "QIqPGwVWpFLY"
      },
      "id": "QIqPGwVWpFLY"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "9mFdoP0Is2si",
        "outputId": "e1ee4d84-b3c4-4fdd-c999-faf2bba31765",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9mFdoP0Is2si",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount the user's Google Drive as a virtual hard drive so that the PDF of the transcript can be accessed and results saved. This will open up an authorization prompt to all the Colab notebook to access drive. Approve this."
      ],
      "metadata": {
        "id": "-Hqf50s1pNwd"
      },
      "id": "-Hqf50s1pNwd"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXerWPl-oitS",
        "outputId": "81456c84-d5ec-49ca-9414-a5195a450f39"
      },
      "id": "qXerWPl-oitS",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import necessary libraries"
      ],
      "metadata": {
        "id": "pgtqQF1XpfDo"
      },
      "id": "pgtqQF1XpfDo"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3d346512",
      "metadata": {
        "id": "3d346512"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
        "import os\n",
        "import pandas as pdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "import os\n",
        "import ast\n",
        "import time\n",
        "import numpy as np\n",
        "import json\n",
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm\n",
        "import textwrap\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "i3oNEnG8fQfZ"
      },
      "id": "i3oNEnG8fQfZ",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paste in the prompt to be send along with the PDF to ChatGPT. This prompt should include instructions about how the transcript is to be scored on a rubric."
      ],
      "metadata": {
        "id": "s7QL7KAppuit"
      },
      "id": "s7QL7KAppuit"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "e77d87a8",
      "metadata": {
        "id": "e77d87a8"
      },
      "outputs": [],
      "source": [
        "prompt = '''Hi ChatGPT,\n",
        "You are a researcher observing college-level statistics classrooms to record the activities of instructors and students. Your task is to first understand the coding rubric and then code the provided CSV file, which contains the transcript of a 65-minute college-level introductory statistics class.\n",
        "Step 1: Review the Codebook\n",
        "The classroom observation form has separate codes for the instructor and for students. These codes are recorded simultaneously in 2-minute segments based on what the instructor and students are doing. The coding sheet has been uploaded as a PDF for your review.\n",
        "Instructor Codes:\n",
        "Lec (Lecturing): The instructor presents course content, with or without visual aids. This includes talking about topics, explaining concepts, going through slides, or any form of direct teaching of course material. Anything the professor said that is vaguely related to the statistics class is lecturing.\n",
        "RtW (Real-time Writing): The instructor is writing on a chalkboard, whiteboard, overhead projector, etc. Usually coded along with lecturing (Lec).\n",
        "PQ (Poses a Question): The instructor poses a content-related question to the whole class, an individual student, or a small group. Does not include rhetorical questions or questions the instructor answers themselves.\n",
        "ExpA (Explains an Answer): The instructor answers/explains a content-related question.\n",
        "D/V (Demonstration or Video): The instructor shows or conducts a demonstration, video, simulation, or animation explaining or elaborating on course content.\n",
        "1:1 (One-on-One Exchange): The instructor discusses with one or a few students while not paying attention to the rest of the class.\n",
        "Mov (Moving): The instructor moves throughout the classroom, pausing to observe and guide student work.\n",
        "Adm (Administration): The instructor discusses homework, returns tests, reminds students of due dates, etc.\n",
        "Student Codes:\n",
        "List (Listening): Students receive content from the instructor through a lecture, video, or demonstration. Usually coded along with lecturing (Lec) or demonstration/video (D/V). Look for keywords indicating passive reception of information. If the teacher is talking, please imagine the students are listening.\n",
        "AskQ (Asks a Question): A student asks the instructor a question in front of the whole class. Look for keywords such as \"question,\" \"ask.\" Look for question marks (?) or phrases indicating a question is being asked.\n",
        "AnQ (Answers a Question): A student answers a teacher’s question.\n",
        "IndW (Individual Work): Students engage in individual thinking or problem-solving.\n",
        "GrW (Group Work): Students work in groups of 2-6 on a structured assignment, task, project, or other instructor-assigned activity.\n",
        "SmGD (Small Group Discussion): Students engage in discussion with 2-6 peers about a question posed by the instructor.\n",
        "WCD (Whole Class Discussion): Students ask and answer questions in front of the whole class while the instructor facilitates.\n",
        "Coding Instructions:\n",
        "Capture instructor and student behaviors objectively.\n",
        "Circle observed behaviors.\n",
        "If a behavior continues into the next segment, circle the code(s) again.\n",
        "Use the Notes section for information not included in the codes.\n",
        "Print the coding sheets and code tables for reference.\n",
        "Step 2: Instead of sending you to the classroom, I have the transcript of the classroom for you to use to code instructor and student activities in a file. This file that transcribes what has happened in a classroom. Code the Transcript in the file I just uploaded with this message.\n",
        "Structure:\n",
        "People: Indicates whether it is teacher speech, student speech, or silence.\n",
        "Timestamp: Documents the duration in minutes for each speech segment.\n",
        "Speech: Documents what was said by the teacher or student, or notes silence.\n",
        "Procedure:\n",
        "Divide the data into adjacent 2-minute intervals based on the \"Timestamp\" column. Let's start by creating the 2-minute intervals and proceed with the refined behavior coding. The timestamps needs to add up to 2 which often include multiple rows of data.\n",
        "Code Behaviors in Each Interval:\n",
        "For each 2-minute interval, check the \"Speech\" column to identify if any of the behaviors occurred.\n",
        "Use specific keywords and patterns to detect behaviors.\n",
        "Please also use your general knowledge to code behavior if you cannot find specific keywords and patterns to detect behaviors.\n",
        "Aggregate the Results:\n",
        "For each 2-minute interval, aggregate the counts of observed behaviors.\n",
        "Sum up the counts for all intervals to get the total occurrences of each behavior.\n",
        "Calculate Percentages:\n",
        "Divide the total counts of each behavior by the total number of intervals to get the percentage of intervals in which each behavior was observed.\n",
        "Example Calculation:\n",
        "If out of 30 intervals, 15 intervals show the teacher was lecturing, the score for Lec (Lecturing) is 0.5.\n",
        "If students asked a question in 3 out of 30 intervals, the score for AskQ (Asks a Question) is 0.1.\n",
        "If no behavior is observed, the score is zero.\n",
        "Output: Please provide scores for instructor and student activities for the CVS file I uploaded. Please remember percentages cannot be over 100%.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the prompt is correct (since it is hard to read a long horizontal string)"
      ],
      "metadata": {
        "id": "78qrr_DnqNCA"
      },
      "id": "78qrr_DnqNCA"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "b54bf7a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b54bf7a7",
        "outputId": "5dafd229-e929-4664-cc94-148054555618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi ChatGPT,\n",
            "You are a researcher observing\n",
            "college-level statistics classrooms to record the\n",
            "activities of instructors and students. Your task\n",
            "is to first understand the coding rubric and then\n",
            "code the provided CSV file, which contains the\n",
            "transcript of a 65-minute college-level\n",
            "introductory statistics class.\n",
            "Step 1: Review the\n",
            "Codebook\n",
            "The classroom observation form has\n",
            "separate codes for the instructor and for\n",
            "students. These codes are recorded simultaneously\n",
            "in 2-minute segments based on what the instructor\n",
            "and students are doing. The coding sheet has been\n",
            "uploaded as a PDF for your review.\n",
            "Instructor\n",
            "Codes:\n",
            "Lec (Lecturing): The instructor presents\n",
            "course content, with or without visual aids. This\n",
            "includes talking about topics, explaining\n",
            "concepts, going through slides, or any form of\n",
            "direct teaching of course material. Anything the\n",
            "professor said that is vaguely related to the\n",
            "statistics class is lecturing. \n",
            "RtW (Real-time\n",
            "Writing): The instructor is writing on a\n",
            "chalkboard, whiteboard, overhead projector, etc.\n",
            "Usually coded along with lecturing (Lec). \n",
            "PQ\n",
            "(Poses a Question): The instructor poses a\n",
            "content-related question to the whole class, an\n",
            "individual student, or a small group. Does not\n",
            "include rhetorical questions or questions the\n",
            "instructor answers themselves. \n",
            "ExpA (Explains an\n",
            "Answer): The instructor answers/explains a\n",
            "content-related question. \n",
            "D/V (Demonstration or\n",
            "Video): The instructor shows or conducts a\n",
            "demonstration, video, simulation, or animation\n",
            "explaining or elaborating on course content.\n",
            "1:1\n",
            "(One-on-One Exchange): The instructor discusses\n",
            "with one or a few students while not paying\n",
            "attention to the rest of the class.\n",
            "Mov (Moving):\n",
            "The instructor moves throughout the classroom,\n",
            "pausing to observe and guide student work. \n",
            "Adm\n",
            "(Administration): The instructor discusses\n",
            "homework, returns tests, reminds students of due\n",
            "dates, etc. \n",
            "Student Codes:\n",
            "List (Listening):\n",
            "Students receive content from the instructor\n",
            "through a lecture, video, or demonstration.\n",
            "Usually coded along with lecturing (Lec) or\n",
            "demonstration/video (D/V). Look for keywords\n",
            "indicating passive reception of information. If\n",
            "the teacher is talking, please imagine the\n",
            "students are listening. \n",
            "AskQ (Asks a Question): A\n",
            "student asks the instructor a question in front of\n",
            "the whole class. Look for keywords such as\n",
            "\"question,\" \"ask.\" Look for question marks (?) or\n",
            "phrases indicating a question is being asked.\n",
            "AnQ\n",
            "(Answers a Question): A student answers a\n",
            "teacher’s question.\n",
            "IndW (Individual Work):\n",
            "Students engage in individual thinking or problem-\n",
            "solving. \n",
            "GrW (Group Work): Students work in\n",
            "groups of 2-6 on a structured assignment, task,\n",
            "project, or other instructor-assigned activity.\n",
            "SmGD (Small Group Discussion): Students engage in\n",
            "discussion with 2-6 peers about a question posed\n",
            "by the instructor. \n",
            "WCD (Whole Class Discussion):\n",
            "Students ask and answer questions in front of the\n",
            "whole class while the instructor facilitates.\n",
            "Coding Instructions:\n",
            "Capture instructor and\n",
            "student behaviors objectively.\n",
            "Circle observed\n",
            "behaviors.\n",
            "If a behavior continues into the next\n",
            "segment, circle the code(s) again.\n",
            "Use the Notes\n",
            "section for information not included in the codes.\n",
            "Print the coding sheets and code tables for\n",
            "reference.\n",
            "Step 2: Instead of sending you to the\n",
            "classroom, I have the transcript of the classroom\n",
            "for you to use to code instructor and student\n",
            "activities in a file. This file that transcribes\n",
            "what has happened in a classroom. Code the\n",
            "Transcript in the file I just uploaded with this\n",
            "message.\n",
            "Structure:\n",
            "People: Indicates whether it\n",
            "is teacher speech, student speech, or silence.\n",
            "Timestamp: Documents the duration in minutes for\n",
            "each speech segment.\n",
            "Speech: Documents what was\n",
            "said by the teacher or student, or notes silence.\n",
            "Procedure:\n",
            "Divide the data into adjacent 2-minute\n",
            "intervals based on the \"Timestamp\" column. Let's\n",
            "start by creating the 2-minute intervals and\n",
            "proceed with the refined behavior coding. The\n",
            "timestamps needs to add up to 2 which often\n",
            "include multiple rows of data.\n",
            "Code Behaviors in\n",
            "Each Interval:\n",
            "For each 2-minute interval, check\n",
            "the \"Speech\" column to identify if any of the\n",
            "behaviors occurred.\n",
            "Use specific keywords and\n",
            "patterns to detect behaviors.\n",
            "Please also use your\n",
            "general knowledge to code behavior if you cannot\n",
            "find specific keywords and patterns to detect\n",
            "behaviors. \n",
            "Aggregate the Results:\n",
            "For each\n",
            "2-minute interval, aggregate the counts of\n",
            "observed behaviors.\n",
            "Sum up the counts for all\n",
            "intervals to get the total occurrences of each\n",
            "behavior.\n",
            "Calculate Percentages:\n",
            "Divide the total\n",
            "counts of each behavior by the total number of\n",
            "intervals to get the percentage of intervals in\n",
            "which each behavior was observed.\n",
            "Example\n",
            "Calculation:\n",
            "If out of 30 intervals, 15 intervals\n",
            "show the teacher was lecturing, the score for Lec\n",
            "(Lecturing) is 0.5.\n",
            "If students asked a question\n",
            "in 3 out of 30 intervals, the score for AskQ (Asks\n",
            "a Question) is 0.1.\n",
            "If no behavior is observed,\n",
            "the score is zero.\n",
            "Output: Please provide scores\n",
            "for instructor and student activities for the CVS\n",
            "file I uploaded. Please remember percentages\n",
            "cannot be over 100%.\n"
          ]
        }
      ],
      "source": [
        "print('\\n'.join(textwrap.wrap(prompt, width=50, replace_whitespace=False)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch the PDF transcript from the user's Google Drive. Replace the filepath of the file variable to the correct PDF destination. You can use the Folder on the left side of Colab to navigate through the mounted drive's folders and files. (The folder sample_data can be ignored. That just comes with Colab by default)"
      ],
      "metadata": {
        "id": "rw_YFJ-_q9KG"
      },
      "id": "rw_YFJ-_q9KG"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fc2bfbb7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc2bfbb7",
        "outputId": "c7adc2ef-82f7-4178-96a2-304d4365fb9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n"
          ]
        }
      ],
      "source": [
        "file = \"/content/drive/MyDrive/ISEA_Test_Audio/sample_classroom_transcript.pdf\"\n",
        "loader = PyPDFLoader(file)\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test that the PDF was loaded in"
      ],
      "metadata": {
        "id": "7L3dFmmYrRg5"
      },
      "id": "7L3dFmmYrRg5"
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWr1O81crbkN",
        "outputId": "89623a5d-b0a3-4786-8807-48520ac1a214"
      },
      "id": "eWr1O81crbkN",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/drive/MyDrive/ISEA_Test_Audio/sample_classroom_transcript.pdf', 'page': 0}, page_content='T: mobs are large crowds of people Usually mobs are not very happy. When they use the word mob they are angry or upset. Another word: gradually. It means that it will happen slowly or taking place. Moving along little by little. S: Like when babies learn to walk T: Yes like babies. They crawl and stand and eventually walk. T: Budge. It means that you gave in. You agree. You give in. T: Summarizes the meaning of the words above. T; We are going to use our inferring poster, which is on the pocket chart. We can use pictures or illustrations to infer. We infer by using our schema. The chart is color coded. T: S1 S1: They were inﬁghting inside the school. T: write I wander why the people behind the little girl were angry. Let’s begin. Hold that though and let us see if the author will answer our question. The title is the Story of Ruby Bridges. I can infer that the man facing the crowd or mob is trying to keep the people back. Writes this question on the chart. S2: he is ruby bridges dad. T: What makes you think that? T: I can infer the men facing the mob are trying to keep the mob back because they are spreading out their arms. Writes the inference on the chart as her inference. T\\\\: Begins to read the story. S3: I can infer that that is her family. T: How can you infer that? S;3 They have the same skin color. T: Continues to read. S:4: I think this is like Rosa Parks. T: Sounds like you are making a text to text to connection. ’ ')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up the client connection to OpenAI's API. This requires an API key. Put your API key into the Colab's Secret (left hand menu). Name the secret APIOpenAI."
      ],
      "metadata": {
        "id": "dpcLUn_vrs9X"
      },
      "id": "dpcLUn_vrs9X"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve the API key from Colab secrets\n",
        "OPENAI_API_KEY = userdata.get('APIOpenAI')\n",
        "\n",
        "# Set the API key as an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "YCQo-l_6sPrH"
      },
      "id": "YCQo-l_6sPrH",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the PDF content into chunks and store them as vectors."
      ],
      "metadata": {
        "id": "K_d5QA9-sfrQ"
      },
      "id": "K_d5QA9-sfrQ"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "40e23089",
      "metadata": {
        "id": "40e23089",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 50000, chunk_overlap = 0)\n",
        "texts = text_splitter.split_documents(docs)\n",
        "\n",
        "directory = 'index_store'\n",
        "\n",
        "vector_index = FAISS.from_documents(texts, OpenAIEmbeddings())\n",
        "vector_index.save_local(directory)\n",
        "\n",
        "vector_index = FAISS.load_local('index_store', OpenAIEmbeddings(),allow_dangerous_deserialization=True)\n",
        "retriever = vector_index.as_retriever(search_type = \"similarity\", search_kwargs = {\"k\":6})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Send the PDF to Open AI **(There is something wrong at this step. Not sure how to interact with the PDF chunks and how OpenAI expects them to be sent)**"
      ],
      "metadata": {
        "id": "FMHp82Ik2UQ8"
      },
      "id": "FMHp82Ik2UQ8"
    },
    {
      "cell_type": "code",
      "source": [
        "qa_interface = RetrievalQA.from_chain_type(llm = ChatOpenAI(model_name = \"gpt-4-turbo-preview\"), chain_type = \"stuff\", retriever = retriever,\n",
        "                                               return_source_documents = True)"
      ],
      "metadata": {
        "id": "BmyyPBnL2YKT"
      },
      "id": "BmyyPBnL2YKT",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Send the prompt to ChatGPT for rubric scoring"
      ],
      "metadata": {
        "id": "GKGO1RTJzuc_"
      },
      "id": "GKGO1RTJzuc_"
    },
    {
      "cell_type": "code",
      "source": [
        "response = qa_interface('Did you get the File?') #Testing\n",
        "#response = qa_interface(prompt) #Send the rubric scoring prompt"
      ],
      "metadata": {
        "id": "qE1ZHejIzxth"
      },
      "id": "qE1ZHejIzxth",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Return the results from ChatGPT"
      ],
      "metadata": {
        "id": "iUtMKcNEzAfe"
      },
      "id": "iUtMKcNEzAfe"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "78670edd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78670edd",
        "outputId": "270e25d7-e566-44d5-b813-3a2eabe801c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but I can't access or receive files. How can I assist you with your question or topic?\n"
          ]
        }
      ],
      "source": [
        "print(response['result'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CtXIPvYJ2zy1"
      },
      "id": "CtXIPvYJ2zy1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extra code: The following uses the function that Alex created. It may run into issues if we have really large text transcripts."
      ],
      "metadata": {
        "id": "h4ErjlPsgDyg"
      },
      "id": "h4ErjlPsgDyg"
    },
    {
      "cell_type": "code",
      "source": [
        "def send_to_api(prompt):\n",
        "    \"\"\"\n",
        "    This function sends a given prompt to OpenAI's API and retrieves the response.\n",
        "\n",
        "    Args:\n",
        "    prompt (str): A string containing the user's input that needs to be processed by the GPT model.\n",
        "\n",
        "    Returns:\n",
        "    result: The response from OpenAI's API or an error message if the request fails.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize result to None, this will store the API response\n",
        "    result = None\n",
        "\n",
        "    # A loop to attempt the API call multiple times if necessary\n",
        "    i = 1\n",
        "    while result is None:\n",
        "        try:\n",
        "            # Making a request to OpenAI's ChatCompletion API\n",
        "            result = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4\",  # Specifies the GPT model to use\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": prompt}  # The prompt or message for the GPT model\n",
        "                ],\n",
        "                temperature=0.5  # Sets the creativity of the response. Lower is more deterministic.\n",
        "            )\n",
        "\n",
        "        except openai.InvalidRequestError:\n",
        "            # If there is an invalid request, store an error message\n",
        "            result = \"InvalidRequestError\"\n",
        "        except:\n",
        "            # For other errors, wait for 1.5 seconds before retrying\n",
        "            time.sleep(1.5)\n",
        "            pass\n",
        "\n",
        "    # Return the API response or error message\n",
        "    return result\n",
        "\n"
      ],
      "metadata": {
        "id": "-GsoINcef6ez"
      },
      "id": "-GsoINcef6ez",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = \"T: mobs are large crowds of people Usually mobs are not very happy. When they use the word mob they are angry or upset. Another word: gradually. It means that it will happen slowly or taking place. Moving along little by little. S: Like when babies learn to walk T: Yes like babies. They crawl and stand and eventually walk. T: Budge. It means that you gave in. You agree. You give in. T: Summarizes the meaning of the words above. T; We are going to use our inferring poster, which is on the pocket chart. We can use pictures or illustrations to infer. We infer by using our schema. The chart is color coded. T: S1 S1: They were inﬁghting inside the school. T: write I wander why the people behind the little girl were angry. Let’s begin. Hold that though and let us see if the author will answer our question. The title is the Story of Ruby Bridges. I can infer that the man facing the crowd or mob is trying to keep the people back. Writes this question on the chart. S2: he is ruby bridges dad. T: What makes you think that? T: I can infer the men facing the mob are trying to keep the mob back because they are spreading out their arms. Writes the inference on the chart as her inference. T\\\\: Begins to read the story. S3: I can infer that that is her family. T: How can you infer that? S;3 They have the same skin color. T: Continues to read. S:4: I think this is like Rosa Parks. T: Sounds like you are making a text to text to connection.\"\n",
        "prompt = prompt + transcript"
      ],
      "metadata": {
        "id": "r2hGdI_-f7eP"
      },
      "id": "r2hGdI_-f7eP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = send_to_api(prompt)\n",
        "result"
      ],
      "metadata": {
        "id": "iRJ-OSxEgLD6"
      },
      "id": "iRJ-OSxEgLD6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.choices[0].message['content']"
      ],
      "metadata": {
        "id": "E19okV5mgOld"
      },
      "id": "E19okV5mgOld",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are functions"
      ],
      "metadata": {
        "id": "lP4EyzzTlUWd"
      },
      "id": "lP4EyzzTlUWd"
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_and_send(pdf_path, prompt):\n",
        "    loader = PyPDFLoader(file)\n",
        "    docs = loader.load()\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 50000, chunk_overlap = 0)\n",
        "    texts = text_splitter.split_documents(docs)\n",
        "\n",
        "    directory = 'index_store'\n",
        "\n",
        "    vector_index = FAISS.from_documents(texts, OpenAIEmbeddings())\n",
        "    vector_index.save_local(directory)\n",
        "\n",
        "    vector_index = FAISS.load_local('index_store', OpenAIEmbeddings())\n",
        "    retriever = vector_index.as_retriever(search_type = \"similarity\", search_kwargs = {\"k\":6})\n",
        "    qa_interface = RetrievalQA.from_chain_type(llm = ChatOpenAI(model_name = \"gpt-4-turbo-preview\"), chain_type = \"stuff\", retriever = retriever,\n",
        "                                                   return_source_documents = True)\n",
        "\n",
        "    response = qa_interface(prompt)\n",
        "\n",
        "    return response['result']"
      ],
      "metadata": {
        "id": "-i3yVygglWGQ"
      },
      "id": "-i3yVygglWGQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}